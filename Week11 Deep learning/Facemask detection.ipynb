{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf9e6daf-ef1d-4ab0-ab03-f1fa3a73cb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ilango\\AppData\\Local\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2c4fdb5-7266-47a5-a83d-046be1528a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76819664-5ef5-4b41-9eb3-aef8c62eb82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images manually (this skips the Unicode error)...\n",
      "Skipping broken file: 0_0_œ¬‘ÿ.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-23 132115.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-23 132400.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-24 171804.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-24 172039.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-24 202509.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-24 205216.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-24 215234.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-24 215615.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-24 220536.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-24 222124.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-24 224833.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-24 225329.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-24 225427.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-25 150422.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-25 150847.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-25 150921.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-25 185823.png\n",
      "Skipping broken file: 0_0_≈˙◊¢ 2020-02-25 190026.png\n",
      "Skipping broken file: 1_0_≈˙◊¢ 2020-02-24 202935.png\n",
      "Skipping broken file: 1_0_≈˙◊¢ 2020-02-24 215624.png\n",
      "Skipping broken file: 1_0_≈˙◊¢ 2020-02-24 224914.png\n",
      "Skipping broken file: 1_0_≈˙◊¢ 2020-02-25 151918.png\n",
      "Successfully loaded 3823 images!\n"
     ]
    }
   ],
   "source": [
    "# 1. Configuration\n",
    "DATA_PATH = r\"C:\\mask_data\"  # Your C drive path\n",
    "IMG_SIZE = 224\n",
    "classes = ['mask', 'nomask']\n",
    "\n",
    "def load_data_manually(path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for category in classes:\n",
    "        folder_path = os.path.join(path, category)\n",
    "        label = classes.index(category)\n",
    "        for img_name in os.listdir(folder_path):\n",
    "            try:\n",
    "                img_path = os.path.join(folder_path, img_name)\n",
    "                # cv2 is more robust against weird Windows filenames\n",
    "                image = cv2.imread(img_path)\n",
    "                image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "                data.append(image)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping broken file: {img_name}\")\n",
    "                continue\n",
    "    return np.array(data) / 255.0, np.array(labels)\n",
    "\n",
    "print(\"Loading images manually (this skips the Unicode error)...\")\n",
    "X, y = load_data_manually(DATA_PATH)\n",
    "print(f\"Successfully loaded {len(X)} images!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "903eff08-e68d-469b-95bf-ca3dea8dd4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ilango\\AppData\\Local\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ilango\\AppData\\Local\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ilango\\AppData\\Local\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Build Model\n",
    "base_model = tf.keras.applications.MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False \n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "592420d4-fdb3-453a-a5b7-36e0e3f6960e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\Ilango\\AppData\\Local\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ilango\\AppData\\Local\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "96/96 [==============================] - 48s 416ms/step - loss: 0.1004 - accuracy: 0.9637 - val_loss: 0.2172 - val_accuracy: 0.9268\n",
      "Epoch 2/10\n",
      "96/96 [==============================] - 37s 388ms/step - loss: 0.0442 - accuracy: 0.9866 - val_loss: 0.2426 - val_accuracy: 0.9124\n",
      "Epoch 3/10\n",
      "96/96 [==============================] - 37s 390ms/step - loss: 0.0264 - accuracy: 0.9908 - val_loss: 0.2609 - val_accuracy: 0.9281\n",
      "Epoch 4/10\n",
      "96/96 [==============================] - 37s 389ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.2092 - val_accuracy: 0.9386\n",
      "Epoch 5/10\n",
      "96/96 [==============================] - 37s 390ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 0.2692 - val_accuracy: 0.9268\n",
      "Epoch 6/10\n",
      "96/96 [==============================] - 37s 388ms/step - loss: 0.0114 - accuracy: 0.9957 - val_loss: 0.2541 - val_accuracy: 0.9307\n",
      "Epoch 7/10\n",
      "96/96 [==============================] - 37s 388ms/step - loss: 0.0118 - accuracy: 0.9951 - val_loss: 0.3508 - val_accuracy: 0.9176\n",
      "Epoch 8/10\n",
      "96/96 [==============================] - 38s 398ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.2152 - val_accuracy: 0.9477\n",
      "Epoch 9/10\n",
      "96/96 [==============================] - 38s 399ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.2980 - val_accuracy: 0.9320\n",
      "Epoch 10/10\n",
      "96/96 [==============================] - 39s 411ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.1687 - val_accuracy: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1aea69f1fc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Training\n",
    "model.fit(X, y, epochs=10, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29745bbc-eb36-4047-8b95-aea58a61bf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ilango\\AppData\\Local\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as mask_detector_model.h5!\n"
     ]
    }
   ],
   "source": [
    "# Save the model so we don't have to train it again\n",
    "model.save(\"mask_detector_model.h5\")\n",
    "print(\"Model saved as mask_detector_model.h5!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "765d1887-4bf0-44e6-bb44-b2685c741c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "054996be-5728-476f-9667-20b522cfa220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load your trained model\n",
    "model = load_model(\"mask_detector_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaddf061-5f60-4cbf-849c-b0f9759eb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use OpenCV's built-in face detector\n",
    "face_clsfr = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eddafc18-d29b-4e64-9932-98a04f3e6136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Camera... If screen is black, try waving your hand.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 1. Load your model\n",
    "model = load_model(\"mask_detector_model.h5\")\n",
    "face_clsfr = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt2.xml')\n",
    "\n",
    "# 2. Reset Camera with specific width/height\n",
    "source = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "source.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "source.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "print(\"Starting Camera... If screen is black, try waving your hand.\")\n",
    "\n",
    "while True:\n",
    "    ret, img = source.read()\n",
    "    \n",
    "    # If the frame is empty, we skip the rest of the loop\n",
    "    if not ret or img is None:\n",
    "        continue \n",
    "    \n",
    "    img = cv2.flip(img, 1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_clsfr.detectMultiScale(gray, 1.1, 5, minSize=(80, 80))  \n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_img = img[y:y+h, x:x+w]\n",
    "        resized = cv2.resize(face_img, (224, 224))\n",
    "        normalized = resized / 255.0\n",
    "        reshaped = np.reshape(normalized, (1, 224, 224, 3))\n",
    "        \n",
    "        prediction = model.predict(reshaped, verbose=0)\n",
    "        prob = prediction[0][0]\n",
    "        \n",
    "        # Determine Label\n",
    "        label = 1 if prob > 0.5 else 0 \n",
    "        text = \"NO MASK\" if label == 1 else \"MASK\"\n",
    "        color = (0, 0, 255) if label == 1 else (0, 255, 0)\n",
    "\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(img, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    # Force the window to show something even if no face is found\n",
    "    cv2.imshow('Face Mask Detector', img)\n",
    "    \n",
    "    # Use waitKey(10) instead of 1 to give the CPU more time to draw the frame\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "source.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b7e13-45eb-44c9-aaea-31332f0fb183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
